{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5847,"status":"ok","timestamp":1704191746240,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"UmmnXI44nhqy"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\psyki\\Downloads\\.conda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["# importing libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":662,"status":"ok","timestamp":1704191749610,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"LiNxaWmjuoUr"},"outputs":[],"source":["data = pd.read_csv('dataset/ner_dataset.csv', encoding='latin1')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704191749610,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"Jzsog9F4n0-W","outputId":"ed497211-fd85-4bf8-e3ed-abc6ad64b486"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1763,"status":"ok","timestamp":1704191751366,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"EWoV2MZ9o4KK"},"outputs":[],"source":["# filling null values in Sentence # column\n","data = data.fillna(method='ffill')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":414,"status":"ok","timestamp":1704191751776,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"jHDWx2h7tbE_"},"outputs":[],"source":["# # filtering sentences\n","# def getSentenceId(num_sentences=10000):\n","#     ids = []\n","#     for i in range(num_sentences):\n","#         ids.append(f'Sentence: {i+1}')\n","#     return ids\n","\n","# data = data.loc[data['Sentence #'].isin(getSentenceId())]"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704191751777,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"2c2vJ3XNpEya","outputId":"e0574902-2653-4981-9e72-0fbb9b4402cf"},"outputs":[{"data":{"text/plain":["(1048575, 4)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# shape of the data\n","data.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704191751777,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"Tj4pCxhxpIXL","outputId":"94b9b50b-b3b0-4f61-d762-7d3d5028eb43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of words = 35177\n"]}],"source":["# number of unique words\n","words = list(set(data['Word'].values))\n","num_words = len(words)\n","print(f'Number of words = {num_words}')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1704191751777,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"TkgIbOChpcNm","outputId":"c5d44929-c7dd-4a1d-aa39-fe2377dabf09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of tags = 17\n"]}],"source":["tags = list(set(data['Tag'].values))\n","num_tags = len(tags)\n","print(f\"Number of tags = {num_tags}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704191751777,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"6oNiN76npmRW","outputId":"d31b961a-76cb-472d-d225-14ce497a56f8"},"outputs":[{"data":{"text/plain":["Tag\n","O        887908\n","B-geo     37644\n","B-tim     20333\n","B-org     20143\n","I-per     17251\n","B-per     16990\n","I-org     16784\n","B-gpe     15870\n","I-geo      7414\n","I-tim      6528\n","B-art       402\n","B-eve       308\n","I-art       297\n","I-eve       253\n","B-nat       201\n","I-gpe       198\n","I-nat        51\n","Name: count, dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# occurrences of tags in sentences\n","data['Tag'].value_counts()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1704191751777,"user":{"displayName":"Gaurav Sharma","userId":"08743796051962088819"},"user_tz":-330},"id":"jXMm3Xnxpz70"},"outputs":[],"source":["# creating a class to create sentences given a dataset\n","\n","class sentenceGetter(object):\n","\n","    def __init__(self, data):\n","\n","        # assigning data to class attribute\n","        self.data = data\n","\n","        # defining a function to extract sentences in the given format from the data\n","        agg_func = lambda s: [(w,p,t) for w,p,t in zip(s['Word'].values.tolist(),\n","                                                       s['POS'].values.tolist(),\n","                                                       s['Tag'].values.tolist())]\n","\n","        # applying this function to each sentence group\n","        self.grouped = self.data.groupby(['Sentence #']).apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","\n","\n","# getting all the sentences from the data\n","getter = sentenceGetter(data)\n","sentences = getter.sentences"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Plot sentence by length\n","plt.hist([len(s) for s in sentences], bins=50)\n","plt.title('Token per sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# creating word tokens\n","\n","# word to token dict\n","word2idx = {w:i+2 for i,w in enumerate(words)}\n","word2idx['PAD'] = 0\n","word2idx['UNK'] = 1\n","\n","# token to word dict\n","idx2word = {i:w for w,i in word2idx.items()}"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# creating tag tokens\n","\n","# tag to token dict\n","tag2idx = {t:i+1 for i,t in enumerate(tags)}\n","tag2idx['PAD'] = 0\n","\n","# token to tag dict\n","idx2tag = {i:t for t,i in tag2idx.items()}"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# creating the x and y data by replacing the words with tokens and padding the sequence\n","from tensorflow.keras.utils import pad_sequences\n","\n","x = [[word2idx[w[0]] for w in s] for s in sentences]\n","x = pad_sequences(x, maxlen=75, padding='post', value=word2idx['PAD'])\n","\n","y = [[tag2idx[w[2]] for w in s] for s in sentences]\n","y = pad_sequences(y, maxlen=75, padding='post', value=tag2idx['PAD'])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# converting the tags to one hot encoding\n","from tensorflow.keras.utils import to_categorical\n","y = to_categorical(y)\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# splitting the data into train and test\n","from sklearn.model_selection import train_test_split\n","xtrain, xtest, ytrain, ytest = train_test_split(np.asarray(x), np.asarray(y), test_size=0.2, random_state=21)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Raw sentence\n","Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . \n","\n","Raw tags\n","O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O \n","\n","Converted sentence\n","[10687 11544 22105 29221  5044  1983 19863 10679 16557 11127 13122  7383\n","  4784 15232  1541 11127  6265 11544 23462 17018 18524  6640 30776 24304\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0] \n","\n","Converted tag\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]]\n"]}],"source":["# checking sentences and tags before and after convertion\n","\n","print('Raw sentence')\n","print(f\"{' '.join([w[0] for w in sentences[0]])} \\n\")\n","\n","print('Raw tags')\n","print(f\"{' '.join([w[2] for w in sentences[0]])} \\n\")\n","\n","print('Converted sentence')\n","print(f\"{x[0]} \\n\")\n","\n","print('Converted tag')\n","print(f\"{y[0]}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Modelling (bi-LSTM + CRF)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow-addons in c:\\users\\psyki\\downloads\\.conda\\lib\\site-packages (0.22.0)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\psyki\\downloads\\.conda\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n","Requirement already satisfied: packaging in c:\\users\\psyki\\downloads\\.conda\\lib\\site-packages (from tensorflow-addons) (23.2)\n"]}],"source":["!pip install tensorflow-addons"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# importing layers\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, TimeDistributed\n","from tensorflow.keras.models import Model\n","from tensorflow_addons.layers import CRF\n","from tensorflow_addons.losses import SigmoidFocalCrossEntropy"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["maxlen = 75\n","word_dims = len(words)+2\n","embedding_dims = 200\n","label_length = len(tags)+1"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["def build_model(maxlen=maxlen, input_dim=word_dims, embedding_dims=embedding_dims, label_length=label_length):\n","    \n","    # defining input\n","    input = Input(shape=(maxlen,), name='input')\n","    \n","    # get embeddings\n","    embeddings = Embedding(\n","        input_dim=input_dim,\n","        output_dim=embedding_dims,\n","        mask_zero=True,\n","        name='embedding'\n","    )(input)\n","    \n","    # passing the embeddings to stacked bi-LSTMs\n","    output_sequences = Bidirectional(LSTM(50, return_sequences=True), name='lstm_1')(embeddings)\n","    output_sequences = Bidirectional(LSTM(50, return_sequences=True), name='lstm_2')(output_sequences)\n","    \n","    # applying dense units for data compressions\n","    dense_output = TimeDistributed(Dense(25, activation='relu'), name='dense')(output_sequences)\n","    \n","    # applying the CRF layer to dense output\n","    predicted_sequence, potentials, sequence_length, crf_kernel = CRF(label_length, name='crf')(dense_output)\n","    \n","    # defining the model\n","    model = Model(input,potentials)\n","    \n","    # compiling the model\n","    model.compile(\n","        loss=SigmoidFocalCrossEntropy(),\n","        optimizer='adam'\n","    )\n","    \n","    # return the model\n","    return model"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input (InputLayer)          [(None, 75)]              0         \n","                                                                 \n"," embedding (Embedding)       (None, 75, 200)           7035800   \n","                                                                 \n"," lstm_1 (Bidirectional)      (None, 75, 100)           100400    \n","                                                                 \n"," lstm_2 (Bidirectional)      (None, 75, 100)           60400     \n","                                                                 \n"," dense (TimeDistributed)     (None, 75, 25)            2525      \n","                                                                 \n"," crf (CRF)                   [(None, 75),              828       \n","                              (None, 75, 18),                    \n","                              (None,),                           \n","                              (18, 18)]                          \n","                                                                 \n","=================================================================\n","Total params: 7199953 (27.47 MB)\n","Trainable params: 7199953 (27.47 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model = build_model()\n","model.summary()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# callbacks\n","save_model = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='ner_crf.h5',\n","    monitor='val_loss',\n","    save_weights_only=True,\n","    save_best_only=True,\n","    verbose=1\n",")\n","\n","es = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    verbose=1\n",")\n","\n","callbacks = [save_model, es]"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","WARNING:tensorflow:Gradients do not exist for variables ['chain_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['chain_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['chain_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['chain_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","38/38 [==============================] - ETA: 0s - loss: 0.8442\n","Epoch 1: val_loss improved from inf to 0.54554, saving model to ner_crf.h5\n","38/38 [==============================] - 64s 1s/step - loss: 0.8442 - val_loss: 0.5455\n","Epoch 2/50\n","38/38 [==============================] - ETA: 0s - loss: 0.4772\n","Epoch 2: val_loss improved from 0.54554 to 0.40480, saving model to ner_crf.h5\n","38/38 [==============================] - 47s 1s/step - loss: 0.4772 - val_loss: 0.4048\n","Epoch 3/50\n","38/38 [==============================] - ETA: 0s - loss: 0.3589\n","Epoch 3: val_loss improved from 0.40480 to 0.31667, saving model to ner_crf.h5\n","38/38 [==============================] - 49s 1s/step - loss: 0.3589 - val_loss: 0.3167\n","Epoch 4/50\n","38/38 [==============================] - ETA: 0s - loss: 0.2847\n","Epoch 4: val_loss improved from 0.31667 to 0.25225, saving model to ner_crf.h5\n","38/38 [==============================] - 50s 1s/step - loss: 0.2847 - val_loss: 0.2522\n","Epoch 5/50\n","38/38 [==============================] - ETA: 0s - loss: 0.2263\n","Epoch 5: val_loss improved from 0.25225 to 0.20083, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.2263 - val_loss: 0.2008\n","Epoch 6/50\n","38/38 [==============================] - ETA: 0s - loss: 0.1794\n","Epoch 6: val_loss improved from 0.20083 to 0.15949, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.1794 - val_loss: 0.1595\n","Epoch 7/50\n","38/38 [==============================] - ETA: 0s - loss: 0.1418\n","Epoch 7: val_loss improved from 0.15949 to 0.12685, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.1418 - val_loss: 0.1268\n","Epoch 8/50\n","38/38 [==============================] - ETA: 0s - loss: 0.1120\n","Epoch 8: val_loss improved from 0.12685 to 0.10098, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.1120 - val_loss: 0.1010\n","Epoch 9/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0881\n","Epoch 9: val_loss improved from 0.10098 to 0.08045, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.0881 - val_loss: 0.0804\n","Epoch 10/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0693\n","Epoch 10: val_loss improved from 0.08045 to 0.06565, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.0693 - val_loss: 0.0656\n","Epoch 11/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0537\n","Epoch 11: val_loss improved from 0.06565 to 0.05205, saving model to ner_crf.h5\n","38/38 [==============================] - 52s 1s/step - loss: 0.0537 - val_loss: 0.0520\n","Epoch 12/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0409\n","Epoch 12: val_loss improved from 0.05205 to 0.04342, saving model to ner_crf.h5\n","38/38 [==============================] - 53s 1s/step - loss: 0.0409 - val_loss: 0.0434\n","Epoch 13/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0319\n","Epoch 13: val_loss improved from 0.04342 to 0.03745, saving model to ner_crf.h5\n","38/38 [==============================] - 53s 1s/step - loss: 0.0319 - val_loss: 0.0375\n","Epoch 14/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0279\n","Epoch 14: val_loss improved from 0.03745 to 0.03126, saving model to ner_crf.h5\n","38/38 [==============================] - 52s 1s/step - loss: 0.0279 - val_loss: 0.0313\n","Epoch 15/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0217\n","Epoch 15: val_loss improved from 0.03126 to 0.03035, saving model to ner_crf.h5\n","38/38 [==============================] - 50s 1s/step - loss: 0.0217 - val_loss: 0.0303\n","Epoch 16/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0179\n","Epoch 16: val_loss improved from 0.03035 to 0.02757, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.0179 - val_loss: 0.0276\n","Epoch 17/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0148\n","Epoch 17: val_loss did not improve from 0.02757\n","38/38 [==============================] - 49s 1s/step - loss: 0.0148 - val_loss: 0.0286\n","Epoch 18/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0127\n","Epoch 18: val_loss improved from 0.02757 to 0.02663, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.0127 - val_loss: 0.0266\n","Epoch 19/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0114\n","Epoch 19: val_loss improved from 0.02663 to 0.02605, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.0114 - val_loss: 0.0260\n","Epoch 20/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0097\n","Epoch 20: val_loss did not improve from 0.02605\n","38/38 [==============================] - 51s 1s/step - loss: 0.0097 - val_loss: 0.0266\n","Epoch 21/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0083\n","Epoch 21: val_loss did not improve from 0.02605\n","38/38 [==============================] - 51s 1s/step - loss: 0.0083 - val_loss: 0.0287\n","Epoch 22/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0086\n","Epoch 22: val_loss improved from 0.02605 to 0.02543, saving model to ner_crf.h5\n","38/38 [==============================] - 52s 1s/step - loss: 0.0086 - val_loss: 0.0254\n","Epoch 23/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0070\n","Epoch 23: val_loss did not improve from 0.02543\n","38/38 [==============================] - 52s 1s/step - loss: 0.0070 - val_loss: 0.0286\n","Epoch 24/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0060\n","Epoch 24: val_loss did not improve from 0.02543\n","38/38 [==============================] - 50s 1s/step - loss: 0.0060 - val_loss: 0.0316\n","Epoch 25/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0053\n","Epoch 25: val_loss did not improve from 0.02543\n","38/38 [==============================] - 50s 1s/step - loss: 0.0053 - val_loss: 0.0335\n","Epoch 26/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0099\n","Epoch 26: val_loss improved from 0.02543 to 0.02360, saving model to ner_crf.h5\n","38/38 [==============================] - 50s 1s/step - loss: 0.0099 - val_loss: 0.0236\n","Epoch 27/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0083\n","Epoch 27: val_loss improved from 0.02360 to 0.02219, saving model to ner_crf.h5\n","38/38 [==============================] - 51s 1s/step - loss: 0.0083 - val_loss: 0.0222\n","Epoch 28/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0059\n","Epoch 28: val_loss did not improve from 0.02219\n","38/38 [==============================] - 50s 1s/step - loss: 0.0059 - val_loss: 0.0249\n","Epoch 29/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0051\n","Epoch 29: val_loss did not improve from 0.02219\n","38/38 [==============================] - 49s 1s/step - loss: 0.0051 - val_loss: 0.0267\n","Epoch 30/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0045\n","Epoch 30: val_loss did not improve from 0.02219\n","38/38 [==============================] - 48s 1s/step - loss: 0.0045 - val_loss: 0.0332\n","Epoch 31/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0045\n","Epoch 31: val_loss did not improve from 0.02219\n","38/38 [==============================] - 50s 1s/step - loss: 0.0045 - val_loss: 0.0303\n","Epoch 32/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0039\n","Epoch 32: val_loss did not improve from 0.02219\n","38/38 [==============================] - 49s 1s/step - loss: 0.0039 - val_loss: 0.0329\n","Epoch 33/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0036\n","Epoch 33: val_loss did not improve from 0.02219\n","38/38 [==============================] - 49s 1s/step - loss: 0.0036 - val_loss: 0.0365\n","Epoch 34/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0035\n","Epoch 34: val_loss did not improve from 0.02219\n","38/38 [==============================] - 49s 1s/step - loss: 0.0035 - val_loss: 0.0359\n","Epoch 35/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0032\n","Epoch 35: val_loss did not improve from 0.02219\n","38/38 [==============================] - 49s 1s/step - loss: 0.0032 - val_loss: 0.0406\n","Epoch 36/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0029\n","Epoch 36: val_loss did not improve from 0.02219\n","38/38 [==============================] - 49s 1s/step - loss: 0.0029 - val_loss: 0.0429\n","Epoch 37/50\n","38/38 [==============================] - ETA: 0s - loss: 0.0027\n","Epoch 37: val_loss did not improve from 0.02219\n","38/38 [==============================] - 49s 1s/step - loss: 0.0027 - val_loss: 0.0482\n","Epoch 37: early stopping\n"]}],"source":["history = model.fit(xtrain, ytrain, validation_data=(xtest, ytest), callbacks=callbacks, epochs=50, batch_size=1024)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# loading trained weights\n","model.load_weights('ner_crf.h5')"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["<keras.src.engine.input_layer.InputLayer at 0x298fc6cfa00>"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# eval_model\n","model.get_layer('input')"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["# eval_model\n","def build_eval_model(model):\n","    \n","    # intermediate model\n","    int_model = Model(model.get_layer('input').input,model.get_layer('dense').output)\n","    \n","    # getting output from the crf layer\n","    predicted_sequence, potentials, sequence_length, crf_kernel = model.get_layer('crf')(int_model.output)\n","    \n","    # defining evaluation model\n","    eval_model = Model(int_model.input, predicted_sequence)\n","    \n","    return eval_model"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["eval_model = build_eval_model(model)\n","ypred = eval_model.predict(xtest)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["array([3411])"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["np.random.choice(range(xtest.shape[0]), 1)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["7"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["np.count_nonzero(np.array([1,2,2,2,3,4,5,0,0,0,0,0,0,0,0,0,0]))"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["'1 2 3'"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["' '.join(('1','2','3'))"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["# checking the predictions\n","def check_prediction(n=1):\n","    \n","    # getting a random text from the test data\n","    idx = np.random.choice(range(xtest.shape[0]), n, replace=False)\n","    \n","    for i in idx:\n","        \n","        sentence = xtest[i]\n","        tags = np.argmax(ytest[i],axis=-1)\n","        pred = ypred[i]\n","        text_len = np.count_nonzero(sentence)\n","        \n","        sentence = sentence[:text_len]\n","        tags = tags[:text_len]\n","        pred = pred[:text_len]\n","        \n","        sentence = [idx2word[t] for t in sentence]\n","        tags = [idx2tag[t] for t in tags]\n","        pred = [idx2tag[t] for t in pred]\n","\n","        print(f\"Sentence {i}\")\n","        print(\"Word | Actual tag | Predicted tag\")\n","        print(\"-\"*30)\n","        for j in zip(sentence,tags,pred):\n","            print(f\"{' | '.join(j)}\")\n","    pass"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence 1475\n","Word | Actual tag | Predicted tag\n","------------------------------\n","She | O | I-gpe\n","said | O | B-art\n","she | O | I-per\n","would | O | PAD\n","seek | O | O\n","charges | O | B-tim\n","of | O | I-gpe\n","betrayal | O | B-art\n","of | O | I-per\n","national | O | PAD\n","interests | O | O\n","and | O | B-tim\n","exceeding | O | I-gpe\n","authority | O | B-art\n",". | O | I-per\n"]}],"source":["check_prediction()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOZ65VG5ab+mlSP2VRk1Xxa","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
